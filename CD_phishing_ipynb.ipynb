{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuPeres/MotorFlawPrediction/blob/main/CD_phishing_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive #importar do drive\n",
        "\n",
        "#CLASSIFICADORES\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix"
      ],
      "metadata": {
        "id": "IkfkuPmwXFxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/archiveCD/CD_P1/phishing.csv')\n",
        "df_train.head()"
      ],
      "metadata": {
        "id": "T5MJ4J0NXKys",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binarize = ['UsingIP','ShortURL','Symbol@','Redirecting//','PrefixS9uffix-','DomainRegLen','Favicon','NonStdPort','HTTPSDomainURL','RequestURL','InfoEmail','AbnormalURL', 'StatusBarCust', 'DisableRightClick', 'UsingPopupWindow', 'IframeRedirection',  'AgeofDomain', 'DNSRecording', 'PageRank', 'GoogleIndex', 'class']\n",
        "for classe in binarize:\n",
        "    df_train[classe] = [0 if x== -1 else 1 for x in df_train[classe]]#-1=0, 1=1\n",
        "\n",
        "adapt = ['LongURL','SubDomains','HTTPS','AnchorURL','LinksInScriptTags','WebsiteTraffic','LinksPointingToPage']\n",
        "for tipo in adapt:\n",
        "    df_train[tipo] = df_train[tipo].map({-1: 0, 0: 1, 1: 2})"
      ],
      "metadata": {
        "id": "6WLh89j0Z6I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_drop = ['Index']\n",
        "df_train.drop(to_drop, axis=1, inplace=True)\n",
        "X = df_train.drop(['class'], axis=1)\n",
        "y = df_train['class']"
      ],
      "metadata": {
        "id": "6c6Cm6hHek7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.value_counts() #Balanceado"
      ],
      "metadata": {
        "id": "kEkkBK74H9MJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aplicando o classificador KNN para o Kfold com 10 splits"
      ],
      "metadata": {
        "id": "0MGs0NI8DFav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=6)\n",
        "fold_knn = StratifiedKFold(n_splits=10)\n",
        "accuracy_knn = np.array([])\n",
        "roc_scores_knn= []\n",
        "\n",
        "for i, (train, test) in enumerate(fold_knn.split(X, y), 1):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=i*12)\n",
        "    knn.fit(X.iloc[train], y.iloc[train])\n",
        "    y_pred = knn.predict(X.iloc[test])\n",
        "    accuracy = accuracy_score(y[test], y_pred)\n",
        "\n",
        "    # Calcula os Scores ROC AUC\n",
        "    y_pred_proba = knn.predict(X.iloc[test])\n",
        "    roc_score = roc_auc_score(y[test], y_pred_proba)\n",
        "    roc_scores_knn.append(roc_score)\n",
        "\n",
        "    mc=confusion_matrix(y[test], y_pred)\n",
        "\n",
        "    print(f'Matriz confusão: \\n {mc}')\n",
        "    print(f\"\\n ROC AUC Score: {roc_score*100:,.2f}%\")\n",
        "    print(\"Accuracy KNN : %.2f%% \\n\" % (accuracy *100.0))\n",
        "    accuracy_knn = np.append(accuracy_knn, accuracy)\n",
        "\n",
        "accuracy_media = np.mean(accuracy_knn)\n",
        "desvio_padrao = np.std(accuracy_knn)\n",
        "\n",
        "avg_roc_score = sum(roc_scores_knn) / len(roc_scores_knn)\n",
        "roc_std = np.std(roc_scores_knn)\n",
        "\n",
        "\n",
        "print(f'\\nAcurácia média KNN: {accuracy_media*100:,.2f}%\\nDesvio padrão: {desvio_padrao*100:,.2f}%')\n",
        "\n",
        "print(f\"\\n ROC AUC Score médio: {avg_roc_score*100:,.2f}%\")\n",
        "print(f\"Desvio padrão do Score ROC AUC: {roc_std*100:,.2f}%\")\n"
      ],
      "metadata": {
        "id": "V3Iih6UNelxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Normalizando"
      ],
      "metadata": {
        "id": "-a6VMfpUDNvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "df_norm = pd.DataFrame(scaler.fit_transform(X), columns = X.columns)"
      ],
      "metadata": {
        "id": "mXtDB5sADRXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extração de variáveis"
      ],
      "metadata": {
        "id": "NYMtJGakFJ0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_collinear_features(x, y, threshold):\n",
        "    corr_matrix = x.corr().abs() #calcula a correlação absoluta (já que -1 é tão importante quanto 1) entre as colunas.\n",
        "    target_corr = abs(x.corrwith(y)) #calcula a correlação absoluta de cada coluna com a classe target.\n",
        "\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)) #analisa somente o triângulo acima da diagonal principal para evitar redundância nas iterações.\n",
        "\n",
        "    drop_cols = []\n",
        "    for column in upper.columns:\n",
        "        correlated_cols = upper.index[upper[column] > threshold].tolist()\n",
        "        if correlated_cols:\n",
        "            least_corr_col = min(correlated_cols, key=lambda col: target_corr[col]) # de duas features de alta correlação, seleciona a feature que tem menor correlação com a classe target para ser excluída.\n",
        "            drop_cols.append(least_corr_col) #guarda o nome das features a serem retiradas\n",
        "\n",
        "    x = x.drop(columns=drop_cols) #retira as features listadas.\n",
        "    return x"
      ],
      "metadata": {
        "id": "4oYpu7U7FSMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rc = remove_collinear_features ((X),y, 0.9) #Considerando acima de 0.9 como correlação direta/inversa (valor absoluto).\n",
        "rc"
      ],
      "metadata": {
        "id": "NHgNrXuTFQKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De forma visual\n",
        "\n"
      ],
      "metadata": {
        "id": "Mvvzy6yWGVJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "g = sns.clustermap(df_norm.corr(),\n",
        "                   method = 'complete',\n",
        "                   cmap   = 'RdBu',\n",
        "                   annot  = True,\n",
        "                   annot_kws = {'size': 8}\n",
        ")\n",
        "plt.setp(g.ax_heatmap.get_xticklabels(), rotation=25);\n",
        "'''\n",
        "corr = df_norm.corr()\n",
        "styled_corr = corr.style.background_gradient(cmap='coolwarm')\n",
        "styled_corr\n",
        "mask = np.zeros_like(corr, dtype=bool)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "corr[mask] = np.nan\n",
        "(corr\n",
        " .style\n",
        " .background_gradient(cmap='coolwarm', axis=None, vmin=-1, vmax=1)\n",
        " .highlight_null(color='#f1f1f1')\n",
        " .format(precision=3))"
      ],
      "metadata": {
        "id": "0f_KFzNDG4k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Seleção de atributos"
      ],
      "metadata": {
        "id": "p2eRma0iLIrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cor_selection(X, y, num_feat):\n",
        "  cor_list = []\n",
        "  feature_name = X.columns.tolist()\n",
        "  for i in feature_name:\n",
        "    cor = np.corrcoef(X[i], y)[0,1]\n",
        "    cor_list.append(cor)\n",
        "\n",
        "  column_count = len(X.columns)\n",
        "  cor_feature = X.columns[np.argsort(np.abs(cor_list))][(column_count-num_feat):].tolist()\n",
        "  return cor_feature"
      ],
      "metadata": {
        "id": "9vd6E5I_LQvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_select = cor_selection(rc, y, 50)   #Lista a quantidade de atributos requisitada quanto a sua correlação com a classe Target, de maneira crescente\n",
        "feat_select"
      ],
      "metadata": {
        "id": "wN9jLJLzLfGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_selected = rc[feat_select]\n",
        "X_selected"
      ],
      "metadata": {
        "id": "kAwqHDqzOlv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RandomForestClassifier"
      ],
      "metadata": {
        "id": "JoAIKfAgHFw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_models = []\n",
        "\n",
        "for i in range(10):\n",
        "\n",
        "  X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_selected, y, test_size=0.3, random_state= i* 12)\n",
        "\n",
        "  rf = RandomForestClassifier(n_estimators=100, criterion='entropy' , random_state= i * 12)  # Usando os estados testados anteriormente\n",
        "  rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "  trained_models.append(rf)\n",
        "  print(f\"Random Forest {i+1} treinado com um random state igual a {i*12}.\")"
      ],
      "metadata": {
        "id": "QeUs5bD8OiTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "roc_scores = []\n",
        "for i, model in enumerate(trained_models):\n",
        "\n",
        "    y_pred = model.predict(X_test_rf)\n",
        "\n",
        "    # Calcula as acurácias\n",
        "    accuracy = accuracy_score(y_test_rf, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    # Calcula os Scores ROC AUC\n",
        "    y_pred_proba = model.predict_proba(X_test_rf)\n",
        "    roc_score = roc_auc_score(y_test_rf, y_pred_proba[:,1])\n",
        "    roc_scores.append(roc_score)\n",
        "\n",
        "    mc2=confusion_matrix(y_test_rf, y_pred)\n",
        "\n",
        "    print(f'Matriz confusão: \\n {mc2}')\n",
        "    print(f\"Treino do RandomForest utilizado {i+1}:\")\n",
        "    print(f\"Acurácia: {accuracy*100:,.2f}%\")\n",
        "    print(f\"ROC AUC Score: {roc_score*100:,.2f}%\\n\")\n",
        "\n",
        "\n",
        "avg_accuracy = sum(accuracies) / len(accuracies)\n",
        "avg_roc_score = sum(roc_scores) / len(roc_scores)\n",
        "\n",
        "accuracy_std = np.std(accuracies)\n",
        "roc_std = np.std(roc_scores)\n",
        "\n",
        "\n",
        "print(f\"Acurácia média: {avg_accuracy*100:,.2f}%\")\n",
        "print(f\"Desvio padrão da acurácia: {accuracy_std*100:,.2f}%\")\n",
        "print()\n",
        "print(f\"ROC AUC Score médio: {avg_roc_score*100:,.2f}%\")\n",
        "print(f\"Desvio padrão do Score ROC AUC: {roc_std*100:,.2f}%\")"
      ],
      "metadata": {
        "id": "3lvYSqprPTPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análise dos resultados"
      ],
      "metadata": {
        "id": "Lddi698TPvGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import wilcoxon\n",
        "\n",
        "alpha = 0.05\n",
        "_, p = wilcoxon(accuracy_knn, accuracies)\n",
        "print(p)\n",
        "if p > alpha:\n",
        "  print('Mesma distribuição (Não rejeita H0)')\n",
        "else:\n",
        "  print('Distribuições diferentes (Rejeita H0)')"
      ],
      "metadata": {
        "id": "ruTubfSGPfPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "re1 = pd.DataFrame(accuracies)\n",
        "re1['classifier'] = 'C1'\n",
        "\n",
        "re2 = pd.DataFrame(accuracy_knn)\n",
        "re2['classifier'] = 'C2'\n",
        "\n",
        "result_clf = pd.concat([re1, re2], axis=0, ignore_index=True)\n",
        "result_clf.columns = ['acc', 'classifier']\n",
        "result_clf\n",
        "\n",
        "sns.displot(result_clf, x='acc',kind=\"kde\", fill=True, hue=\"classifier\")"
      ],
      "metadata": {
        "id": "gVEFSmIfPynC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analisando o gráfico de acurácia apresentado acima, é correto afirmar que o primeiro cenário (C1) possui menor dispersão quando comparado ao segundo cenário (C2), isso porque C1 possui um desvio padrão de apenas 0,45%, enquanto C2 possui 1,28% de desvio padrão. Além disso, é importante ressaltar que apesar dos desvios padrões obtidos por cada cenário, ambos apresentaram uma excelente capacidade em distinguir entre as classes positiva e negativa em um problema de classificação binária, o indicativo dessa característica é o ROC AUC Score que para C1 foi de 99,67% e para C2 95,28%, comprovando que ambos demonstraram precisão e obtiveram poucos erros."
      ],
      "metadata": {
        "id": "bdm2czHnR2K9"
      }
    }
  ]
}